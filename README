ПРОЕКТ ПО АВТОДОЛНЕНИЮ ТЕКСТОВ ДЛЯ ПРИЛОЖЕНИЙ НА МОБИЛЬНЫХ УСТРОЙСТВАХ

Активация виртуальной среды, установка зависимостей
# Домашняя машина на windows
#.venv\Scripts\activate.bat 

source .venv/bin/activate
pip install -r requirements.txt

#Скачивание сырых данных
python -m src.get_raw_data

#Предобработка данных
python -m src.preprocess_data

#Подготовка данных для обучения
python -m src.tokenize_split_data


#Подготовка LSTM-модели
python -m src.lstm_model

#Обучение LSTM-модели
python -m src.lstm_train

#Оценка LSTM-модели
python -m src.eval_lstm

#Оценка DistilGPT2
python -m src.eval_transformer_pipeline


Выводы по проделанной работе:

- LSTM-модель показала относительно адекватные результаты на задаче автодополнения текста. Относительно потмоу что даже человек не дополнит эти твитты. Твитты это чаще всего не особо осмысенный поток сознания.
- DistilGPT2, наверное благодаря предобучению на большом корпусе текстов, продемонстрировала сравнительно похожие результаты, может, чуть лучшие, если мы про смысл.
- По метрикам схожая картина: 0.06 VS 0.06. Одинаково плохо, но логично и ожидаемо. Loss GPT2 7.4887, а у LSTM 4.5987.
- Для мобильных приложений LSTM может быть предпочтительнее из-за меньшего размера и скорости работы, особенно если дообучить её на более логичных текстах и на большем корпусе.
- Изначально проект выполнялся на машине с NVIDIA GeForce RTX 3060, с 27 млн параметров обучение и тесты шли гораздо быстрее, чем на T4. 