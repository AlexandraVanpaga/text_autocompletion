{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74df9a95",
   "metadata": {},
   "source": [
    "### Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa97e9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rouge_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, optim\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrouge_score\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rouge_scorer\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizerFast\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mevaluate\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rouge_score'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import re\n",
    "import pandas as pd \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Subset, random_split, Dataset\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from rouge_score import rouge_scorer\n",
    "from transformers import BertTokenizerFast\n",
    "import evaluate\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from typing import Tuple, List, Optional\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import json\n",
    "import tempfile\n",
    "from tqdm import tqdm as tqdm_auto\n",
    "from config import PATHS, MODEL_CONFIG, TRAINING_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb44f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03326d2",
   "metadata": {},
   "source": [
    "### Деление на строки и очистка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cefc350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество твитов после разделения: 688679\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\\nis upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds\\nmy whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Kwesidei not the whole crew \\nNeed a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@twittera que me muera ? \\nspring break in plain city... it's snowing \\nI just re-pierced my ears</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@octolinz16 It it counts, idk why I did either. you never talk to me anymore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@smarrison i would've been the first, but i didn't have a gun.    not really though, zac snyder's just a doucheclown.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                   text\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\\nis upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\n",
       "1                                                                                             @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds\\nmy whole body feels itchy and like its on fire\n",
       "2                                                                                                                        @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.\n",
       "3                                                                                                                                                                                             @Kwesidei not the whole crew \\nNeed a hug\n",
       "4                                                                                                                                   @LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?\n",
       "5                                                                                                                                                                                                   @Tatiana_K nope they didn't have it\n",
       "6                                                                                                                                     @twittera que me muera ? \\nspring break in plain city... it's snowing \\nI just re-pierced my ears\n",
       "7                                                                                                                                        @caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .\n",
       "8                                                                                                                                                          @octolinz16 It it counts, idk why I did either. you never talk to me anymore\n",
       "9                                                                                                                 @smarrison i would've been the first, but i didn't have a gun.    not really though, zac snyder's just a doucheclown."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# читаем текст из файла\n",
    "with open(r\"C:\\Users\\Alexandra\\Desktop\\text_autocompletion\\data\\raw_dataset.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Разделяем текст на твиты: каждый твит начинается с @username и до следующего юзернейма\n",
    "tweets_raw = re.split(r'(?<=\\n)(?=@\\w+\\s)|^(?=@\\w+\\s)', text, flags=re.MULTILINE)\n",
    "\n",
    "# Убираем пустые строки и лишние пробелы\n",
    "tweets_cleaned = [tw.strip() for tw in tweets_raw if tw.strip()]\n",
    "\n",
    "# Создаём DataFrame\n",
    "df = pd.DataFrame(tweets_cleaned, columns=[\"text\"])\n",
    "\n",
    "# Вывод первых 10 твитов\n",
    "print(f\"Количество твитов после разделения: {len(df)}\")\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec95be1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\\nis upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "      <td>awww, that's a bummer. you shoulda got david carr of third day to do it. d is upset that he can't update his facebook by texting it... and might cry as a result school today also. blah!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds\\nmy whole body feels itchy and like its on fire</td>\n",
       "      <td>i dived many times for the ball. managed to save 50 the rest go out of bounds my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am i here? because i can't see you all over there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Kwesidei not the whole crew \\nNeed a hug</td>\n",
       "      <td>not the whole crew need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?</td>\n",
       "      <td>hey long time no see! yes.. rains a bit ,only a bit lol , i'm fine thanks , how's you ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "      <td>nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@twittera que me muera ? \\nspring break in plain city... it's snowing \\nI just re-pierced my ears</td>\n",
       "      <td>que me muera ? spring break in plain city... it's snowing i just repierced my ears</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .</td>\n",
       "      <td>i couldn't bear to watch it. and i thought the ua loss was embarrassing . . . . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@octolinz16 It it counts, idk why I did either. you never talk to me anymore</td>\n",
       "      <td>it it counts, idk why i did either. you never talk to me anymore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@smarrison i would've been the first, but i didn't have a gun.    not really though, zac snyder's just a doucheclown.</td>\n",
       "      <td>i would've been the first, but i didn't have a gun. not really though, zac snyder's just a doucheclown.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                   text  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\\nis upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!   \n",
       "1                                                                                             @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds\\nmy whole body feels itchy and like its on fire   \n",
       "2                                                                                                                        @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.   \n",
       "3                                                                                                                                                                                             @Kwesidei not the whole crew \\nNeed a hug   \n",
       "4                                                                                                                                   @LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?   \n",
       "5                                                                                                                                                                                                   @Tatiana_K nope they didn't have it   \n",
       "6                                                                                                                                     @twittera que me muera ? \\nspring break in plain city... it's snowing \\nI just re-pierced my ears   \n",
       "7                                                                                                                                        @caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .   \n",
       "8                                                                                                                                                          @octolinz16 It it counts, idk why I did either. you never talk to me anymore   \n",
       "9                                                                                                                 @smarrison i would've been the first, but i didn't have a gun.    not really though, zac snyder's just a doucheclown.   \n",
       "\n",
       "                                                                                                                                                                                  text_clean  \n",
       "0  awww, that's a bummer. you shoulda got david carr of third day to do it. d is upset that he can't update his facebook by texting it... and might cry as a result school today also. blah!  \n",
       "1                                                               i dived many times for the ball. managed to save 50 the rest go out of bounds my whole body feels itchy and like its on fire  \n",
       "2                                                                                              no, it's not behaving at all. i'm mad. why am i here? because i can't see you all over there.  \n",
       "3                                                                                                                                                              not the whole crew need a hug  \n",
       "4                                                                                                    hey long time no see! yes.. rains a bit ,only a bit lol , i'm fine thanks , how's you ?  \n",
       "5                                                                                                                                                                   nope they didn't have it  \n",
       "6                                                                                                         que me muera ? spring break in plain city... it's snowing i just repierced my ears  \n",
       "7                                                                                                          i couldn't bear to watch it. and i thought the ua loss was embarrassing . . . . .  \n",
       "8                                                                                                                           it it counts, idk why i did either. you never talk to me anymore  \n",
       "9                                                                                    i would've been the first, but i didn't have a gun. not really though, zac snyder's just a doucheclown.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Функция предобработки твита\n",
    "def preprocess_text(text: str) -> str:\n",
    "    # Удаляем юзернеймы\n",
    "    text = re.sub(r'@\\w+\\s+', '', text)\n",
    "    # Удаляем ссылки\n",
    "    text = re.sub(r\"(https?://\\S+|www\\.\\S+)\", \"\", text)\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Убираем всё кроме латиницы, цифр, важных знаков препинания и пробелов\n",
    "    text = re.sub(r\"[^a-z0-9\\s\\.,!?']\", \"\", text)\n",
    "    # Нормализация пробелов\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "df[\"text_clean\"] = df[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# Убираем пустые строки\n",
    "df = df[df[\"text_clean\"].str.strip() != \"\"]\n",
    "\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cfd5430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Статистика по количеству слов в тексте:\n",
      "Среднее: 29.21\n",
      "Медиана: 22.00\n",
      "5-й перцентиль: 4.00\n",
      "95-й перцентиль: 81.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#  Статистика по количеству слов\n",
    "word_counts = [len(text.split()) for text in df[\"text_clean\"]]\n",
    "\n",
    "\n",
    "print(\"\\nСтатистика по количеству слов в тексте:\")\n",
    "print(f\"Среднее: {np.mean(word_counts):.2f}\")\n",
    "print(f\"Медиана: {np.median(word_counts):.2f}\")\n",
    "print(f\"5-й перцентиль: {np.percentile(word_counts, 5):.2f}\")\n",
    "print(f\"95-й перцентиль: {np.percentile(word_counts, 95):.2f}\")\n",
    "\n",
    "# Гистограмма распределения длины\n",
    "plt.hist(word_counts, bins=50, edgecolor='black')\n",
    "plt.title(\"Распределение количества слов в текстах\")\n",
    "plt.xlabel(\"Количество слов\")\n",
    "plt.ylabel(\"Частота\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94fb4b1",
   "metadata": {},
   "source": [
    "###  Токенизация, подготовка X, y, сплит на трейн-валидацию-тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53758621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Создание datasets для обучения модели\n",
      "============================================================\n",
      "\n",
      "Загрузка данных из: C:\\Users\\Alexandra\\Desktop\\text_autocompletion\\data\\clean_dataset.csv\n",
      "Загружено строк: 688588\n",
      "GPU: NVIDIA GeForce RTX 3060\n",
      "\n",
      "Разбиение данных...\n",
      "Train: 550870, Val: 68859, Test: 68859\n",
      "\n",
      "Загрузка Fast токенизатора...\n",
      "\n",
      "Создание datasets...\n",
      "Train dataset:\n",
      "Токенизация батчами...\n",
      "Загружено 442643 строк\n",
      "Val dataset:\n",
      "Токенизация батчами...\n",
      "Загружено 55362 строк\n",
      "Test dataset:\n",
      "Токенизация батчами...\n",
      "Загружено 55267 строк\n",
      "\n",
      "Создание dataloaders...\n",
      "\n",
      "Сохранение...\n",
      "✓ Сохранено в: C:\\Users\\Alexandra\\Desktop\\text_autocompletion\\data\\split\n",
      "\n",
      "============================================================\n",
      "✓ Готово!\n",
      "  Train batches: 3459\n",
      "  Val batches: 433\n",
      "  Test batches: 432\n",
      "  Device: cuda\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Токенизация и разбиение данных на train/val/test.\n",
    "\"\"\"\n",
    "\n",
    "# Dataset с Fast Tokenizer\n",
    "\n",
    "\n",
    "class TextGenerationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset для генерации текста с поддержкой быстрой токенизации.\n",
    "    Разбивает текст на prefix и target для обучения модели автодополнения.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        texts: List[str], \n",
    "        tokenizer: BertTokenizerFast,\n",
    "        max_length: int = 64,\n",
    "        min_length: int = 16\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.min_length = min_length\n",
    "        \n",
    "        self.samples = []\n",
    "        self.word_boundaries = []\n",
    "        \n",
    "        # Батчевая токенизация - быстрее\n",
    "        print(\"Токенизация батчами...\")\n",
    "        batch_size = 1000\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            \n",
    "            # Батчевая токенизация\n",
    "            encodings = self.tokenizer.batch_encode_plus(\n",
    "                batch_texts,\n",
    "                add_special_tokens=True,\n",
    "                max_length=max_length,\n",
    "                truncation=True,\n",
    "                return_tensors=None\n",
    "            )\n",
    "            \n",
    "            for tokens in encodings['input_ids']:\n",
    "                if len(tokens) >= min_length:\n",
    "                    # Находим границы слов\n",
    "                    tokenized_text = self.tokenizer.convert_ids_to_tokens(tokens)\n",
    "                    word_starts = [0]\n",
    "                    \n",
    "                    for j, token in enumerate(tokenized_text[1:], 1):\n",
    "                        if not token.startswith('##') and token != '[SEP]':\n",
    "                            word_starts.append(j)\n",
    "                    \n",
    "                    if len(tokens) - 1 not in word_starts:\n",
    "                        word_starts.append(len(tokens) - 1)\n",
    "                    \n",
    "                    self.samples.append(tokens)\n",
    "                    self.word_boundaries.append(word_starts)\n",
    "        \n",
    "        print(f\"Загружено {len(self.samples)} строк\")\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        tokens = self.samples[idx]\n",
    "        word_starts = self.word_boundaries[idx]\n",
    "        seq_len = len(tokens)\n",
    "        \n",
    "        target_split = int(seq_len * 0.75)\n",
    "        split_point = min(word_starts, key=lambda x: abs(x - target_split))\n",
    "        split_point = max(split_point, 1)\n",
    "        \n",
    "        prefix = tokens[:split_point]\n",
    "        target = tokens[split_point:]\n",
    "        \n",
    "        prefix_len = int(self.max_length * 0.75)\n",
    "        target_len = self.max_length - prefix_len\n",
    "        \n",
    "        if len(prefix) < prefix_len:\n",
    "            prefix = prefix + [self.tokenizer.pad_token_id] * (prefix_len - len(prefix))\n",
    "        elif len(prefix) > prefix_len:\n",
    "            valid_boundaries = [w for w in word_starts if w <= prefix_len]\n",
    "            if valid_boundaries:\n",
    "                cut_point = max(valid_boundaries)\n",
    "                prefix = tokens[:cut_point]\n",
    "                target = tokens[cut_point:]\n",
    "                if len(prefix) < prefix_len:\n",
    "                    prefix = prefix + [self.tokenizer.pad_token_id] * (prefix_len - len(prefix))\n",
    "        \n",
    "        original_target_len = len(target)\n",
    "        if len(target) < target_len:\n",
    "            target = target + [self.tokenizer.pad_token_id] * (target_len - len(target))\n",
    "        else:\n",
    "            target = target[:target_len]\n",
    "        \n",
    "        attention_mask = [1] * min(original_target_len, target_len) + [0] * max(0, target_len - original_target_len)\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(prefix, dtype=torch.long),\n",
    "            torch.tensor(target, dtype=torch.long),\n",
    "            torch.tensor(attention_mask, dtype=torch.float)\n",
    "        )\n",
    "\n",
    "\n",
    "# Функции для работы с данными\n",
    "\n",
    "\n",
    "def split_data(\n",
    "    df: pd.DataFrame,\n",
    "    text_column: str = 'text'\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Разбивает DataFrame на train, validation и test выборки.\n",
    "    \"\"\"\n",
    "    df_shuffled = df.sample(frac=1, random_state=TRAINING_CONFIG['random_state']).reset_index(drop=True)\n",
    "    \n",
    "    train_df, temp_df = train_test_split(\n",
    "        df_shuffled,\n",
    "        test_size=(TRAINING_CONFIG['val_ratio'] + TRAINING_CONFIG['test_ratio']),\n",
    "        random_state=TRAINING_CONFIG['random_state']\n",
    "    )\n",
    "    \n",
    "    val_size_adjusted = TRAINING_CONFIG['val_ratio'] / (TRAINING_CONFIG['val_ratio'] + TRAINING_CONFIG['test_ratio'])\n",
    "    val_df, test_df = train_test_split(\n",
    "        temp_df,\n",
    "        test_size=(1 - val_size_adjusted),\n",
    "        random_state=TRAINING_CONFIG['random_state']\n",
    "    )\n",
    "    \n",
    "    print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "#  Параметр device принимает torch.device\n",
    "def create_and_save_datasets(\n",
    "    df: pd.DataFrame,\n",
    "    text_column: str = 'text',\n",
    "    device: torch.device = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Создаёт datasets, dataloaders и сохраняет их на диск.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame с текстами\n",
    "        text_column: название колонки с текстом\n",
    "        device: torch.device объект (не строка!)\n",
    "    \"\"\"\n",
    "   \n",
    "    \n",
    "    # Создаём директорию\n",
    "    os.makedirs(PATHS['split_dir'], exist_ok=True)\n",
    "    \n",
    "    # Создаем torch.device объект, если не передан \n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"CPU\")\n",
    "    \n",
    "    print(\"\\nРазбиение данных...\")\n",
    "    train_df, val_df, test_df = split_data(df, text_column)\n",
    "    \n",
    "    print(\"\\nЗагрузка Fast токенизатора...\")\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    print(\"\\nСоздание datasets...\")\n",
    "    train_texts = train_df[text_column].tolist()\n",
    "    val_texts = val_df[text_column].tolist()\n",
    "    test_texts = test_df[text_column].tolist()\n",
    "    \n",
    "    print(\"Train dataset:\")\n",
    "    train_dataset = TextGenerationDataset(\n",
    "        train_texts, \n",
    "        tokenizer, \n",
    "        MODEL_CONFIG['max_length'], \n",
    "        MODEL_CONFIG['min_length']\n",
    "    )\n",
    "    \n",
    "    print(\"Val dataset:\")\n",
    "    val_dataset = TextGenerationDataset(\n",
    "        val_texts, \n",
    "        tokenizer, \n",
    "        MODEL_CONFIG['max_length'], \n",
    "        MODEL_CONFIG['min_length']\n",
    "    )\n",
    "    \n",
    "    print(\"Test dataset:\")\n",
    "    test_dataset = TextGenerationDataset(\n",
    "        test_texts, \n",
    "        tokenizer, \n",
    "        MODEL_CONFIG['max_length'], \n",
    "        MODEL_CONFIG['min_length']\n",
    "    )\n",
    "    \n",
    "    print(\"\\nСоздание dataloaders...\")\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TRAINING_CONFIG['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=TRAINING_CONFIG['num_workers'],\n",
    "        pin_memory=(device.type == 'cuda' and TRAINING_CONFIG['pin_memory'])\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=TRAINING_CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=TRAINING_CONFIG['num_workers'],\n",
    "        pin_memory=(device.type == 'cuda' and TRAINING_CONFIG['pin_memory'])\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=TRAINING_CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=TRAINING_CONFIG['num_workers'],\n",
    "        pin_memory=(device.type == 'cuda' and TRAINING_CONFIG['pin_memory'])\n",
    "    )\n",
    "    \n",
    "    print(\"\\nСохранение...\")\n",
    "    with open(PATHS['train_dataset'], 'wb') as f:\n",
    "        pickle.dump(train_dataset, f)\n",
    "    \n",
    "    with open(PATHS['val_dataset'], 'wb') as f:\n",
    "        pickle.dump(val_dataset, f)\n",
    "    \n",
    "    with open(PATHS['test_dataset'], 'wb') as f:\n",
    "        pickle.dump(test_dataset, f)\n",
    "    \n",
    "    with open(PATHS['tokenizer'], 'wb') as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "    \n",
    "    print(f\"✓ Сохранено в: {PATHS['split_dir']}\")\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, tokenizer, device\n",
    "\n",
    "\n",
    "\n",
    "# Главная функция\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Основная функция для создания и сохранения datasets.\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Создание datasets для обучения модели\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"\\nЗагрузка данных из: {PATHS['clean_data']}\")\n",
    "    df = pd.read_csv(PATHS['clean_data'], encoding='utf-8')\n",
    "    print(f\"Загружено строк: {len(df)}\")\n",
    "    \n",
    "    # Передаем torch.device объект вместо строки 'cuda' \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    train_loader, val_loader, test_loader, tokenizer, device = create_and_save_datasets(\n",
    "        df=df,\n",
    "        text_column='text',\n",
    "        device=device  # Правильно: torch.device объект\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✓ Готово!\")\n",
    "    print(f\"  Train batches: {len(train_loader)}\")\n",
    "    print(f\"  Val batches: {len(val_loader)}\")\n",
    "    print(f\"  Test batches: {len(test_loader)}\")\n",
    "    print(f\"  Device: {device}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74342f4",
   "metadata": {},
   "source": [
    "### Подготовка LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2149f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LSTM модель для генерации продолжения текста.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from config import MODEL_CONFIG\n",
    "\n",
    "\n",
    "class LSTMTextGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM модель для генерации продолжения текста (1/4 последовательности).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int = None,\n",
    "        embedding_dim: int = None,\n",
    "        hidden_size: int = None,\n",
    "        num_layers: int = None,\n",
    "        dropout: float = None,\n",
    "        pad_token_id: int = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vocab_size: размер словаря (30522 для BERT)\n",
    "            embedding_dim: размерность embedding'ов\n",
    "            hidden_size: размер hidden state LSTM\n",
    "            num_layers: количество LSTM слоёв\n",
    "            dropout: dropout rate\n",
    "            pad_token_id: ID токена padding\n",
    "        \"\"\"\n",
    "        super(LSTMTextGenerator, self).__init__()\n",
    "        \n",
    "        # Используем значения из конфига, если параметры не переданы\n",
    "        self.vocab_size = vocab_size or MODEL_CONFIG['vocab_size']\n",
    "        self.embedding_dim = embedding_dim or MODEL_CONFIG['embedding_dim']\n",
    "        self.hidden_size = hidden_size or MODEL_CONFIG['hidden_size']\n",
    "        self.num_layers = num_layers or MODEL_CONFIG['num_layers']\n",
    "        dropout = dropout if dropout is not None else MODEL_CONFIG['dropout']\n",
    "        self.pad_token_id = pad_token_id if pad_token_id is not None else MODEL_CONFIG['pad_token_id']\n",
    "        \n",
    "        # Embedding слой\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=self.vocab_size,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "            padding_idx=self.pad_token_id\n",
    "        )\n",
    "        \n",
    "        # LSTM слои\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=dropout if self.num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Dropout перед выходным слоем\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Выходной fully connected слой\n",
    "        self.fc = nn.Linear(self.hidden_size, self.vocab_size)\n",
    "        \n",
    "        # Инициализация весов\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Инициализация весов модели умным способом - через Xavier.\"\"\"\n",
    "        # Embedding\n",
    "        nn.init.uniform_(self.embedding.weight, -0.1, 0.1)\n",
    "        \n",
    "        # LSTM\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.zeros_(param)\n",
    "        \n",
    "        # FC layer\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        hidden: Optional[Tuple[torch.Tensor, torch.Tensor]] = None\n",
    "    ) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Args:\n",
    "            input_ids: [batch_size, seq_len] - входные токены\n",
    "            hidden: опциональное начальное hidden state\n",
    "        \n",
    "        Returns:\n",
    "            logits: [batch_size, seq_len, vocab_size] - logits для каждой позиции\n",
    "            hidden: (h_n, c_n) - финальное hidden state\n",
    "        \"\"\"\n",
    "        # Embedding: [batch_size, seq_len, embedding_dim]\n",
    "        embedded = self.embedding(input_ids)\n",
    "        \n",
    "        # LSTM: [batch_size, seq_len, hidden_size]\n",
    "        lstm_out, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        # Dropout\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        \n",
    "        # FC layer: [batch_size, seq_len, vocab_size]\n",
    "        logits = self.fc(lstm_out)\n",
    "        \n",
    "        return logits, hidden\n",
    "    \n",
    "    def generate(\n",
    "        self,\n",
    "        prefix: torch.Tensor,\n",
    "        max_length: int,\n",
    "        temperature: float = None,\n",
    "        top_k: int = None,\n",
    "        repetition_penalty: float = None,\n",
    "        pad_token_id: int = None,\n",
    "        eos_token_id: int = 102  # [SEP] token для BERT\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Генерирует продолжение текста с защитой от повторений.\n",
    "        \n",
    "        Args:\n",
    "            prefix: [batch_size, prefix_len] - префикс (3/4 текста)\n",
    "            max_length: длина генерации (1/4 текста)\n",
    "            temperature: температура для sampling (выше = разнообразнее)\n",
    "            top_k: размер top-k filtering\n",
    "            repetition_penalty: штраф за повторения (>1 = сильнее штраф)\n",
    "            pad_token_id: ID padding токена\n",
    "            eos_token_id: ID токена конца последовательности\n",
    "        \n",
    "        Returns:\n",
    "            generated: [batch_size, max_length] - сгенерированные токены\n",
    "        \"\"\"\n",
    "        # Используем значения из конфига, если параметры не переданы\n",
    "        temperature = temperature if temperature is not None else MODEL_CONFIG['temperature']\n",
    "        top_k = top_k if top_k is not None else MODEL_CONFIG['top_k']\n",
    "        repetition_penalty = repetition_penalty if repetition_penalty is not None else MODEL_CONFIG['repetition_penalty']\n",
    "        pad_token_id = pad_token_id if pad_token_id is not None else self.pad_token_id\n",
    "        \n",
    "        self.eval()\n",
    "        batch_size = prefix.size(0)\n",
    "        device = prefix.device\n",
    "        \n",
    "        # Получаем hidden state от префикса (3/4 текста)\n",
    "        with torch.no_grad():\n",
    "            _, hidden = self.forward(prefix)\n",
    "        \n",
    "        #  Находим последний НЕ-PAD токен в каждой последовательности\n",
    "        mask = (prefix != pad_token_id)  # [batch_size, seq_len]\n",
    "        lengths = mask.sum(dim=1)  # Реальная длина каждой последовательности\n",
    "        \n",
    "        # Проверка: если вся последовательность из PAD (не должно быть, но на всякий случай)\n",
    "        lengths = torch.clamp(lengths, min=1)\n",
    "        \n",
    "        # Извлекаем последний реальный токен для каждого примера в батче"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd9582b",
   "metadata": {},
   "source": [
    "### Оценка архитектуры модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c04c27",
   "metadata": {},
   "source": [
    "Опытном бутем было проверено, что:\n",
    "- target_len - длина генерируемой последовательности должна быть приблизительно 16. Этот вывод был сделано после анализа длин текстов в датасете.\n",
    "- embedding_dim=256, hidden_size=512,num_layers=2 и 5 эпох дают приблизитеьно такое же качество на текущих данных, как 10 эпох и 3 скрытых слоя. Так что оставляем более легковесные параметры.\n",
    "- если использовать argmax, а не top-k при генерации следующего токена, то получается очень плохой результат. Поэтому в модель интегрированы следующие особенности генерации с защитой от повторений:\n",
    "\n",
    "1) Temperature sampling - контролирует \"креативность\"\n",
    "2) Top-k filtering - выбирает из топ-50 токенов\n",
    "3) Repetition penalty - штрафует повторяющиеся токены\n",
    "\n",
    "\n",
    "Оптимизация:\n",
    "1) Xavier инициализация для стабильного обучения\n",
    "2) Dropout для регуляризации\n",
    "3) Padding aware (игнорирует pad токены)\n",
    "4) NLP-шный классический оптимизатов Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4f933c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "АРХИТЕКТУРА МОДЕЛИ\n",
      "============================================================\n",
      "Параметров: 27,149,626\n",
      "Vocab size: 30522\n",
      "Embedding dim: 256\n",
      "Hidden size: 512\n",
      "Num layers: 2\n",
      "Dropout: 0.2\n",
      "============================================================\n",
      "\n",
      "Тест Forward Pass:\n",
      "Input shape:  torch.Size([4, 48])\n",
      "Logits shape: torch.Size([4, 48, 30522])\n",
      "\n",
      "Тест Generation:\n",
      "Generated shape: torch.Size([4, 16])\n",
      "\n",
      "Модель готова к обучению\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Параметры\n",
    "    vocab_size = 30522  # BERT vocab size\n",
    "    batch_size = 4\n",
    "    prefix_len = 48  # 75% от 64\n",
    "    target_len = 16  # 25% от 64\n",
    "    \n",
    "    # Создаём модель\n",
    "    model = LSTMTextGenerator(\n",
    "        vocab_size=vocab_size,\n",
    "        embedding_dim=256,\n",
    "        hidden_size=512,\n",
    "        num_layers=2,\n",
    "        dropout=0.2\n",
    "    )\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"АРХИТЕКТУРА МОДЕЛИ\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Параметров: {model.get_num_params():,}\")\n",
    "    print(f\"Vocab size: {vocab_size}\")\n",
    "    print(f\"Embedding dim: 256\")\n",
    "    print(f\"Hidden size: 512\")\n",
    "    print(f\"Num layers: 2\")\n",
    "    print(f\"Dropout: 0.2\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Тестовые данные\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    prefix = torch.randint(0, vocab_size, (batch_size, prefix_len)).to(device)\n",
    "    target = torch.randint(0, vocab_size, (batch_size, target_len)).to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    logits, hidden = model(prefix)\n",
    "    print(f\"\\nТест Forward Pass:\")\n",
    "    print(f\"Input shape:  {prefix.shape}\")\n",
    "    print(f\"Logits shape: {logits.shape}\")  # [4, 48, 30522]\n",
    "    \n",
    "    # Генерация\n",
    "    generated = model.generate(\n",
    "        prefix, \n",
    "        max_length=16, \n",
    "        temperature=0.8, \n",
    "        top_k=50,\n",
    "        repetition_penalty=1.2\n",
    "    )\n",
    "    print(f\"\\nТест Generation:\")\n",
    "    print(f\"Generated shape: {generated.shape}\")  # [4, 16]\n",
    "    \n",
    "    print(\"\\nМодель готова к обучению\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954fbb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "Train: 442643, Val: 55362\n",
      "Device: cuda\n",
      "Параметров: 27,149,626\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89a17f9ecd04acda77bcb30f3826317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/3459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train=5.6798, Val=4.9381, PPL=139.51\n",
      "  ROUGE-1=0.0622, ROUGE-2=0.0031, ROUGE-L=0.0569\n",
      "  Модель сохранена\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd0505e7be543ffafa5a00c787469c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/3459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train=4.8291, Val=4.6869, PPL=108.51\n",
      "  ROUGE-1=0.0649, ROUGE-2=0.0035, ROUGE-L=0.0595\n",
      "  Модель сохранена\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95841c152b84ef998fdb4ab02a2ee32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/3459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train=4.6536, Val=4.5562, PPL=95.22\n",
      "  ROUGE-1=0.0655, ROUGE-2=0.0032, ROUGE-L=0.0606\n",
      "  Модель сохранена\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a391bb1cd2ac491a9388b6863c7777c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/3459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train=4.5659, Val=4.5333, PPL=93.06\n",
      "  ROUGE-1=0.0672, ROUGE-2=0.0043, ROUGE-L=0.0619\n",
      "  Модель сохранена\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5f79d3aa8e445eb3d1f9a9cee55a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/3459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train=4.5098, Val=4.4495, PPL=85.59\n",
      "  ROUGE-1=0.0686, ROUGE-2=0.0053, ROUGE-L=0.0639\n",
      "  Модель сохранена\n",
      "\n",
      "Обучение завершено!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Обучение LSTM модели с ROUGE метриками.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "from rouge_score import rouge_scorer\n",
    "from src.dataset import TextGenerationDataset \n",
    "from src.lstm_model import LSTMTextGenerator\n",
    "from config import PATHS, MODEL_CONFIG, TRAINING_CONFIG\n",
    "\n",
    "\n",
    "def get_last_real_token(prefix, pad_token_id):\n",
    "    \"\"\"\n",
    "    Находит последний НЕ-PAD токен в каждой последовательности батча.\n",
    "    \n",
    "    Args:\n",
    "        prefix: [batch_size, seq_len] - префикс с возможным padding\n",
    "        pad_token_id: ID токена padding\n",
    "    \n",
    "    Returns:\n",
    "        last_tokens: [batch_size, 1] - последние реальные токены\n",
    "    \"\"\"\n",
    "    batch_size = prefix.size(0)\n",
    "    device = prefix.device\n",
    "    \n",
    "    # Маска реальных токенов (не PAD)\n",
    "    mask = (prefix != pad_token_id)  # [batch_size, seq_len]\n",
    "    \n",
    "    # Длина каждой последовательности\n",
    "    lengths = mask.sum(dim=1)  # [batch_size]\n",
    "    \n",
    "    # Защита от полностью PAD последовательностей\n",
    "    lengths = torch.clamp(lengths, min=1)\n",
    "    \n",
    "    # Индексы последних реальных токенов\n",
    "    indices = lengths - 1  # [batch_size]\n",
    "    \n",
    "    # Извлекаем последние реальные токены\n",
    "    last_tokens = prefix[torch.arange(batch_size, device=device), indices]\n",
    "    \n",
    "    return last_tokens.unsqueeze(1)  # [batch_size, 1]\n",
    "\n",
    "\n",
    "# Загрузка данных\n",
    "\n",
    "os.makedirs(PATHS['models_dir'], exist_ok=True)\n",
    "\n",
    "print(\"Загрузка данных...\")\n",
    "with open(PATHS['train_dataset'], 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "with open(PATHS['val_dataset'], 'rb') as f:\n",
    "    val_dataset = pickle.load(f)\n",
    "with open(PATHS['tokenizer'], 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=TRAINING_CONFIG['batch_size'], \n",
    "    shuffle=True, \n",
    "    num_workers=TRAINING_CONFIG['num_workers']\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=TRAINING_CONFIG['batch_size'], \n",
    "    shuffle=False, \n",
    "    num_workers=TRAINING_CONFIG['num_workers']\n",
    ")\n",
    "\n",
    "\n",
    "# Создание модели\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "model = LSTMTextGenerator(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    embedding_dim=MODEL_CONFIG['embedding_dim'],\n",
    "    hidden_size=MODEL_CONFIG['hidden_size'],\n",
    "    num_layers=MODEL_CONFIG['num_layers'],\n",
    "    dropout=MODEL_CONFIG['dropout'],\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    ").to(device)\n",
    "\n",
    "print(f\"Параметров: {model.get_num_params():,}\\n\")\n",
    "\n",
    "\n",
    "# Оптимизация\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=TRAINING_CONFIG['learning_rate'], \n",
    "    weight_decay=TRAINING_CONFIG['weight_decay']\n",
    ")\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min', \n",
    "    factor=TRAINING_CONFIG['scheduler_factor'], \n",
    "    patience=TRAINING_CONFIG['scheduler_patience']\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id, reduction='none')\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "\n",
    "# Обучение\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, TRAINING_CONFIG['num_epochs'] + 1):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for prefix, target, mask in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        prefix, target, mask = prefix.to(device), target.to(device), mask.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        _, hidden = model(prefix)\n",
    "        \n",
    "        #  Берём последний реальный токен, а не PAD\n",
    "        last_real_token = get_last_real_token(prefix, tokenizer.pad_token_id)\n",
    "        decoder_input = torch.cat([last_real_token, target[:, :-1]], dim=1)\n",
    "        \n",
    "        logits, _ = model(decoder_input, hidden)\n",
    "        \n",
    "        loss = criterion(logits.reshape(-1, logits.size(-1)), target.reshape(-1))\n",
    "        loss = (loss * mask.reshape(-1)).sum() / mask.reshape(-1).sum()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), TRAINING_CONFIG['grad_clip'])\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    # Val с ROUGE\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for prefix, target, mask in val_loader:\n",
    "            prefix, target, mask = prefix.to(device), target.to(device), mask.to(device)\n",
    "            \n",
    "            # Loss\n",
    "            _, hidden = model(prefix)\n",
    "            \n",
    "            # ИСПРАВЛЕНИЕ: Берём последний реальный токен\n",
    "            last_real_token = get_last_real_token(prefix, tokenizer.pad_token_id)\n",
    "            decoder_input = torch.cat([last_real_token, target[:, :-1]], dim=1)\n",
    "            \n",
    "            logits, _ = model(decoder_input, hidden)\n",
    "            \n",
    "            loss = criterion(logits.reshape(-1, logits.size(-1)), target.reshape(-1))\n",
    "            loss = (loss * mask.reshape(-1)).sum() / mask.reshape(-1).sum()\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # ROUGE\n",
    "            if len(rouge_scores['rouge1']) < TRAINING_CONFIG['num_rouge_samples']:\n",
    "                generated = model.generate(\n",
    "                    prefix[:32],\n",
    "                    max_length=target.size(1),\n",
    "                    temperature=MODEL_CONFIG['temperature'],\n",
    "                    top_k=MODEL_CONFIG['top_k'],\n",
    "                    repetition_penalty=MODEL_CONFIG['repetition_penalty'],\n",
    "                    pad_token_id=tokenizer.pad_token_id\n",
    "                )\n",
    "                \n",
    "                for i in range(min(32, prefix.size(0))):\n",
    "                    target_text = tokenizer.decode(target[i].cpu().tolist(), skip_special_tokens=True)\n",
    "                    generated_text = tokenizer.decode(generated[i].cpu().tolist(), skip_special_tokens=True)\n",
    "                    \n",
    "                    if len(target_text.strip()) > 0 and len(generated_text.strip()) > 0:\n",
    "                        scores = scorer.score(target_text, generated_text)\n",
    "                        rouge_scores['rouge1'].append(scores['rouge1'].fmeasure)\n",
    "                        rouge_scores['rouge2'].append(scores['rouge2'].fmeasure)\n",
    "                        rouge_scores['rougeL'].append(scores['rougeL'].fmeasure)\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    perplexity = np.exp(val_loss)\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Средние ROUGE\n",
    "    avg_rouge1 = np.mean(rouge_scores['rouge1']) if rouge_scores['rouge1'] else 0.0\n",
    "    avg_rouge2 = np.mean(rouge_scores['rouge2']) if rouge_scores['rouge2'] else 0.0\n",
    "    avg_rougeL = np.mean(rouge_scores['rougeL']) if rouge_scores['rougeL'] else 0.0\n",
    "    \n",
    "    print(f\"Epoch {epoch}: Train={train_loss:.4f}, Val={val_loss:.4f}, PPL={perplexity:.2f}\")\n",
    "    print(f\"  ROUGE-1={avg_rouge1:.4f}, ROUGE-2={avg_rouge2:.4f}, ROUGE-L={avg_rougeL:.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), PATHS['best_model'])\n",
    "        print(\"  Модель сохранена\")\n",
    "\n",
    "print(\"\\nОбучение завершено!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9ada12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexandra\\AppData\\Local\\Temp\\ipykernel_14080\\957172102.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(PATHS['best_model']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ПРИМЕРЫ ГЕНЕРАЦИИ ИЗ VALIDATION SET\n",
      "================================================================================\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Пример 1:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Префикс (75%):    hi miley i love u so much! ur so amzing!!! plz replyfollow me\n",
      "Ground Truth:     it would rlly mean alot\n",
      "Сгенерировано:    ! i wanna see them in!\n",
      "\n",
      "ROUGE-1: 0.0000 | ROUGE-2: 0.0000 | ROUGE-L: 0.0000\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Пример 2:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Префикс (75%):    whhyy mom ' s gone. i already miss her but in week and a half she ' ll be here again so\n",
      "Ground Truth:     .. yay! happiness again xd\n",
      "Сгенерировано:    you will be ok, your love!\n",
      "\n",
      "ROUGE-1: 0.0000 | ROUGE-2: 0.0000 | ROUGE-L: 0.0000\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Пример 3:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Префикс (75%):    wooo!! i think your fabulouss!! i cant tell you how much i love your video of you picking your\n",
      "Ground Truth:     nose!! its a hair flip!\n",
      "Сгенерировано:    own name! quotweet us\n",
      "\n",
      "ROUGE-1: 0.0000 | ROUGE-2: 0.0000 | ROUGE-L: 0.0000\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Пример 4:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Префикс (75%):    we made awesome shirts for st. louis. we thought so anyway. i will make it my profile pic. r u\n",
      "Ground Truth:     in for the next video???\n",
      "Сгенерировано:    ? i ' m going to be happy\n",
      "\n",
      "ROUGE-1: 0.0000 | ROUGE-2: 0.0000 | ROUGE-L: 0.0000\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Пример 5:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Префикс (75%):    hi ava! did u join the jb live chat? i feel\n",
      "Ground Truth:     like dancing in the rain\n",
      "Сгенерировано:    like a twitter!\n",
      "\n",
      "ROUGE-1: 0.2500 | ROUGE-2: 0.0000 | ROUGE-L: 0.2500\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Пример 6:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Префикс (75%):    wow must ' ve taken years of practice to get to this proficiency. i manage to draw geometrical\n",
      "Ground Truth:     shapes after this years lol\n",
      "Сгенерировано:    , or the end of mine\n",
      "\n",
      "ROUGE-1: 0.0000 | ROUGE-2: 0.0000 | ROUGE-L: 0.0000\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Пример 7:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Префикс (75%):    i know what you mean... i ' ll be heading back to buffalo for\n",
      "Ground Truth:     a visit eatfest in july\n",
      "Сгенерировано:    my work on an earide\n",
      "\n",
      "ROUGE-1: 0.0000 | ROUGE-2: 0.0000 | ROUGE-L: 0.0000\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Пример 8:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Префикс (75%):    awl! quoti love you ajia your my worldquot how sweet there were a lot of bfv fans who responded! if you liked bfv let us know why, even if you picked another as your favorite? i\n",
      "Ground Truth:     am finally getting over the flu but remain on the air at wxr\n",
      "Сгенерировано:    just can ' t believe i had to say they were the best friend for\n",
      "\n",
      "ROUGE-1: 0.0741 | ROUGE-2: 0.0000 | ROUGE-L: 0.0741\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Пример 9:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Префикс (75%):    ooohhh! what kinda animals do u have!? ps heyyyyyy!!! srry i didn ' t come on here earlier. i was sleeeeeeeeping! luv u!\n",
      "Ground Truth:     !! i never hear the timer bell on my oven go off!!\n",
      "Сгенерировано:    i want to go out by a long day in a row of an hour\n",
      "\n",
      "ROUGE-1: 0.1538 | ROUGE-2: 0.0000 | ROUGE-L: 0.1538\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Пример 10:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Префикс (75%):    john is talking about the who and the colts hope you are not missing it mtv movie awards tonight 3am\n",
      "Ground Truth:     must wake up to watch it live\n",
      "Сгенерировано:    ! but not feeling well today\n",
      "\n",
      "ROUGE-1: 0.0000 | ROUGE-2: 0.0000 | ROUGE-L: 0.0000\n",
      "\n",
      "================================================================================\n",
      "СРЕДНИЕ ROUGE ДЛЯ ПРИМЕРОВ:\n",
      "  ROUGE-1: 0.0478\n",
      "  ROUGE-2: 0.0000\n",
      "  ROUGE-L: 0.0478\n",
      "================================================================================\n",
      "\n",
      "Примеры сохранены в: C:\\Users\\Alexandra\\Desktop\\text_autocompletion\\models\\validation_examples.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Просмотр примеров генерации из validation set.\n",
    "\"\"\"\n",
    "\n",
    "# Параметры\n",
    "\n",
    "example_params = {\n",
    "    'num_examples': 10,\n",
    "    'temperature': 0.8,\n",
    "    'top_k': 50,\n",
    "    'repetition_penalty': 1.2\n",
    "}\n",
    "\n",
    "\n",
    "# Загрузка данных и модели\n",
    "\n",
    "\n",
    "print(\"Загрузка данных...\")\n",
    "with open(PATHS['val_dataset'], 'rb') as f:\n",
    "    val_dataset = pickle.load(f)\n",
    "with open(PATHS['tokenizer'], 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=TRAINING_CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Загружаем лучшую модель\n",
    "model = LSTMTextGenerator(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    embedding_dim=MODEL_CONFIG['embedding_dim'],\n",
    "    hidden_size=MODEL_CONFIG['hidden_size'],\n",
    "    num_layers=MODEL_CONFIG['num_layers'],\n",
    "    dropout=MODEL_CONFIG['dropout'],\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(PATHS['best_model']), weights_only=True)\n",
    "model.eval()\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "\n",
    "# Генерация примеров\n",
    "\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ПРИМЕРЫ ГЕНЕРАЦИИ ИЗ VALIDATION SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "num_examples = example_params['num_examples']\n",
    "examples_shown = 0\n",
    "examples_data = []\n",
    "rouge_values = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for prefix, target, mask in val_loader:\n",
    "        if examples_shown >= num_examples:\n",
    "            break\n",
    "        \n",
    "        prefix = prefix.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # Генерируем\n",
    "        generated = model.generate(\n",
    "            prefix,\n",
    "            max_length=target.size(1),\n",
    "            temperature=example_params['temperature'],\n",
    "            top_k=example_params['top_k'],\n",
    "            repetition_penalty=example_params['repetition_penalty'],\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "        \n",
    "        # Показываем примеры\n",
    "        for i in range(min(prefix.size(0), num_examples - examples_shown)):\n",
    "            prefix_text = tokenizer.decode(prefix[i].cpu().tolist(), skip_special_tokens=True)\n",
    "            target_text = tokenizer.decode(target[i].cpu().tolist(), skip_special_tokens=True)\n",
    "            generated_text = tokenizer.decode(generated[i].cpu().tolist(), skip_special_tokens=True)\n",
    "            \n",
    "            # ROUGE для примера\n",
    "            if len(target_text.strip()) > 0 and len(generated_text.strip()) > 0:\n",
    "                scores = scorer.score(target_text, generated_text)\n",
    "                \n",
    "                print(f\"\\n{'─'*80}\")\n",
    "                print(f\"Пример {examples_shown + 1}:\")\n",
    "                print(f\"{'─'*80}\")\n",
    "                print(f\"Префикс (75%):    {prefix_text}\")\n",
    "                print(f\"Ground Truth:     {target_text}\")\n",
    "                print(f\"Сгенерировано:    {generated_text}\")\n",
    "                print(f\"\\nROUGE-1: {scores['rouge1'].fmeasure:.4f} | \"\n",
    "                      f\"ROUGE-2: {scores['rouge2'].fmeasure:.4f} | \"\n",
    "                      f\"ROUGE-L: {scores['rougeL'].fmeasure:.4f}\")\n",
    "                \n",
    "                # Сохраняем как словарь\n",
    "                examples_data.append({\n",
    "                    'example_num': examples_shown + 1,\n",
    "                    'prefix': prefix_text,\n",
    "                    'ground_truth': target_text,\n",
    "                    'generated': generated_text,\n",
    "                    'rouge1': scores['rouge1'].fmeasure,\n",
    "                    'rouge2': scores['rouge2'].fmeasure,\n",
    "                    'rougeL': scores['rougeL'].fmeasure\n",
    "                })\n",
    "                \n",
    "                rouge_values['rouge1'].append(scores['rouge1'].fmeasure)\n",
    "                rouge_values['rouge2'].append(scores['rouge2'].fmeasure)\n",
    "                rouge_values['rougeL'].append(scores['rougeL'].fmeasure)\n",
    "                \n",
    "                examples_shown += 1\n",
    "            \n",
    "            if examples_shown >= num_examples:\n",
    "                break\n",
    "\n",
    "# Средние ROUGE\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"СРЕДНИЕ ROUGE ДЛЯ ПРИМЕРОВ:\")\n",
    "print(f\"  ROUGE-1: {np.mean(rouge_values['rouge1']):.4f}\")\n",
    "print(f\"  ROUGE-2: {np.mean(rouge_values['rouge2']):.4f}\")\n",
    "print(f\"  ROUGE-L: {np.mean(rouge_values['rougeL']):.4f}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Сохраняем примеры в JSON\n",
    "examples_path = os.path.join(PATHS['models_dir'], 'validation_examples.json')\n",
    "with open(examples_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(examples_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Примеры сохранены в: {examples_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03e774a",
   "metadata": {},
   "source": [
    "### Промежуточный вывод: более-менее осмысленно. Я - человек - вряд ли такие текст дополнила бы лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a4c4d2",
   "metadata": {},
   "source": [
    "### Финальная оценка на тест-сете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2aa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка test set...\n",
      "Test samples: 55267\n",
      "Device: cuda\n",
      "\n",
      "Оценка на test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexandra\\AppData\\Local\\Temp\\ipykernel_14080\\2771167583.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(PATHS['best_model']))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec81ada20c34f1499141e826b8e3e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "РЕЗУЛЬТАТЫ НА TEST SET\n",
      "================================================================================\n",
      "Test Loss:       4.4529\n",
      "Test Perplexity: 85.88\n",
      "\n",
      "ROUGE Scores (на 2015 примерах):\n",
      "  ROUGE-1: 0.0728 (±0.1084)\n",
      "  ROUGE-2: 0.0063 (±0.0438)\n",
      "  ROUGE-L: 0.0678 (±0.1028)\n",
      "================================================================================\n",
      "\n",
      "ПРИМЕРЫ ГЕНЕРАЦИИ ИЗ TEST SET\n",
      "================================================================================\n",
      "\n",
      "Пример 1:\n",
      "Префикс: i ' m a guy. of course i ' d laugh at something like that.\n",
      "Ground Truth: how are you today mona?\n",
      "Генерация: yay all tomorrow.\n",
      "ROUGE: R1=0.000, R2=0.000, RL=0.000\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Пример 2:\n",
      "Префикс: ok so somehow ashwee managed to make a whole bottle of purple punky explode all over the bathroom and even some on the carpet i really want to keep watching evangelion or playing gta iv, but i keep passing out.\n",
      "Ground Truth: maybe it ' s a sign i need sleep? but i dun wanna.\n",
      "Генерация: good night, it was a great day! my birthday. going to sleep\n",
      "ROUGE: R1=0.250, R2=0.000, RL=0.250\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Пример 3:\n",
      "Префикс: i know, i know... but i can ' t get my\n",
      "Ground Truth: hair wet!!!\n",
      "Генерация: phone on my twitter.\n",
      "ROUGE: R1=0.000, R2=0.000, RL=0.000\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Пример 4:\n",
      "Префикс: buffy fest sounds like its just what i need cept all my buffy friends are online\n",
      "Ground Truth: noone here likes it\n",
      "Генерация: or the uk. haha\n",
      "ROUGE: R1=0.000, R2=0.000, RL=0.000\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Пример 5:\n",
      "Префикс: easy week then 98 minutes to go before i return to my regularly low prices this song thanks this song has helped me through a lot of bullshit hey people wow i ' m really happy today..........\n",
      "Ground Truth: ...... i just wanted to give yall smiles.\n",
      "Генерация: . it ' s so nice to see how you can be a kid\n",
      "ROUGE: R1=0.105, R2=0.000, RL=0.105\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Пример 6:\n",
      "Префикс: i so badly wish i was there. you guys are my favoritelt3 apparently not sleeping netime soon thx to that music... giving in and watching harpers island... i need my scarepal bec things\n",
      "Ground Truth: just dont feel right. im hoping eric can make it better i recently\n",
      "Генерация: to change my hair, i ' m so bored. but it is the\n",
      "ROUGE: R1=0.160, R2=0.000, RL=0.080\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Пример 7:\n",
      "Префикс: we lost tonight i think they got ya number 2 mel. yo we out 2 see drag me 2 hell\n",
      "Ground Truth: 2mrw? having a neighbourhood dispute\n",
      "Генерация: i think i had to go see\n",
      "ROUGE: R1=0.000, R2=0.000, RL=0.000\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Пример 8:\n",
      "Префикс: i am jealous. all the shows in my area were far away on week nights so i didn ' t get to\n",
      "Ground Truth: see this show have a blast!\n",
      "Генерация: see the movie on bday party\n",
      "ROUGE: R1=0.167, R2=0.000, RL=0.167\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Пример 9:\n",
      "Префикс: the fray were very good but not as good as the killers or nickelback. i haven ' t got any gigs lined up now. crying and sobbing over random gay romance\n",
      "Ground Truth: stories on the net. i feel really silly..\n",
      "Генерация: . ahhhh i hate my phone tooooo\n",
      "ROUGE: R1=0.143, R2=0.000, RL=0.143\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Пример 10:\n",
      "Префикс: lunch? its already 6? lol anyway, i ' m back sis! ran around after the kids all morning... hair blowdried, went to visit unwell friend.\n",
      "Ground Truth: .. she was out shopping... must be feeling better\n",
      "Генерация: is my best friend ever. how to read a comment?\n",
      "ROUGE: R1=0.000, R2=0.000, RL=0.000\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Примеры сохранены в: C:\\Users\\Alexandra\\Desktop\\text_autocompletion\\models\\test_generation_examples.json\n",
      "Оценка завершена\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Оценка LSTM модели на test set.\n",
    "\"\"\"\n",
    "\n",
    "# Загрузка данных и модели\n",
    "\n",
    "\n",
    "print(\"Загрузка test set...\")\n",
    "with open(PATHS['test_dataset'], 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "with open(PATHS['tokenizer'], 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=TRAINING_CONFIG['batch_size'], \n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    ")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Загружаем модель\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "model = LSTMTextGenerator(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    embedding_dim=MODEL_CONFIG['embedding_dim'],\n",
    "    hidden_size=MODEL_CONFIG['hidden_size'],\n",
    "    num_layers=MODEL_CONFIG['num_layers'],\n",
    "    dropout=MODEL_CONFIG['dropout'],\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(PATHS['best_model']), weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id, reduction='none')\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "\n",
    "# Оценка на test set\n",
    "\n",
    "\n",
    "test_loss = 0\n",
    "rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "\n",
    "print(\"\\nОценка на test set...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for prefix, target, mask in tqdm(test_loader, desc=\"Testing\"):\n",
    "        prefix, target, mask = prefix.to(device), target.to(device), mask.to(device)\n",
    "        \n",
    "        # Loss\n",
    "        _, hidden = model(prefix)\n",
    "        decoder_input = torch.cat([prefix[:, -1:], target[:, :-1]], dim=1)\n",
    "        logits, _ = model(decoder_input, hidden)\n",
    "        \n",
    "        loss = criterion(logits.reshape(-1, logits.size(-1)), target.reshape(-1))\n",
    "        loss = (loss * mask.reshape(-1)).sum() / mask.reshape(-1).sum()\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # ROUGE\n",
    "        if len(rouge_scores['rouge1']) < TRAINING_CONFIG['num_rouge_samples']:\n",
    "            generated = model.generate(\n",
    "                prefix[:32],\n",
    "                max_length=target.size(1),\n",
    "                temperature=MODEL_CONFIG['temperature'],\n",
    "                top_k=MODEL_CONFIG['top_k'],\n",
    "                repetition_penalty=MODEL_CONFIG['repetition_penalty'],\n",
    "                pad_token_id=tokenizer.pad_token_id\n",
    "            )\n",
    "            \n",
    "            for i in range(min(32, prefix.size(0))):\n",
    "                target_text = tokenizer.decode(target[i].cpu().tolist(), skip_special_tokens=True)\n",
    "                generated_text = tokenizer.decode(generated[i].cpu().tolist(), skip_special_tokens=True)\n",
    "                \n",
    "                if len(target_text.strip()) > 0 and len(generated_text.strip()) > 0:\n",
    "                    scores = scorer.score(target_text, generated_text)\n",
    "                    rouge_scores['rouge1'].append(scores['rouge1'].fmeasure)\n",
    "                    rouge_scores['rouge2'].append(scores['rouge2'].fmeasure)\n",
    "                    rouge_scores['rougeL'].append(scores['rougeL'].fmeasure)\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_perplexity = np.exp(test_loss)\n",
    "\n",
    "# Средние метрики\n",
    "avg_rouge1 = np.mean(rouge_scores['rouge1'])\n",
    "avg_rouge2 = np.mean(rouge_scores['rouge2'])\n",
    "avg_rougeL = np.mean(rouge_scores['rougeL'])\n",
    "\n",
    "std_rouge1 = np.std(rouge_scores['rouge1'])\n",
    "std_rouge2 = np.std(rouge_scores['rouge2'])\n",
    "std_rougeL = np.std(rouge_scores['rougeL'])\n",
    "\n",
    "# Результаты\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"РЕЗУЛЬТАТЫ НА TEST SET\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Test Loss:       {test_loss:.4f}\")\n",
    "print(f\"Test Perplexity: {test_perplexity:.2f}\")\n",
    "print(f\"\\nROUGE Scores (на {len(rouge_scores['rouge1'])} примерах):\")\n",
    "print(f\"  ROUGE-1: {avg_rouge1:.4f} (±{std_rouge1:.4f})\")\n",
    "print(f\"  ROUGE-2: {avg_rouge2:.4f} (±{std_rouge2:.4f})\")\n",
    "print(f\"  ROUGE-L: {avg_rougeL:.4f} (±{std_rougeL:.4f})\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "\n",
    "# Примеры генерации\n",
    "\n",
    "\n",
    "print(\"\\nПРИМЕРЫ ГЕНЕРАЦИИ ИЗ TEST SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "num_examples = TRAINING_CONFIG['num_examples']\n",
    "examples_shown = 0\n",
    "examples_data = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for prefix, target, mask in test_loader:\n",
    "        if examples_shown >= num_examples:\n",
    "            break\n",
    "        \n",
    "        prefix = prefix.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        generated = model.generate(\n",
    "            prefix,\n",
    "            max_length=target.size(1),\n",
    "            temperature=MODEL_CONFIG['temperature'],\n",
    "            top_k=MODEL_CONFIG['top_k'],\n",
    "            repetition_penalty=MODEL_CONFIG['repetition_penalty'],\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "        \n",
    "        for i in range(min(prefix.size(0), num_examples - examples_shown)):\n",
    "            prefix_text = tokenizer.decode(prefix[i].cpu().tolist(), skip_special_tokens=True)\n",
    "            target_text = tokenizer.decode(target[i].cpu().tolist(), skip_special_tokens=True)\n",
    "            generated_text = tokenizer.decode(generated[i].cpu().tolist(), skip_special_tokens=True)\n",
    "            \n",
    "            if len(target_text.strip()) > 0 and len(generated_text.strip()) > 0:\n",
    "                scores = scorer.score(target_text, generated_text)\n",
    "                \n",
    "                print(f\"\\nПример {examples_shown + 1}:\")\n",
    "                print(f\"Префикс: {prefix_text}\")\n",
    "                print(f\"Ground Truth: {target_text}\")\n",
    "                print(f\"Генерация: {generated_text}\")\n",
    "                print(f\"ROUGE: R1={scores['rouge1'].fmeasure:.3f}, \"\n",
    "                      f\"R2={scores['rouge2'].fmeasure:.3f}, \"\n",
    "                      f\"RL={scores['rougeL'].fmeasure:.3f}\")\n",
    "                print(\"─\"*80)\n",
    "                \n",
    "                # Сохраняем как словарь\n",
    "                examples_data.append({\n",
    "                    'example_num': examples_shown + 1,\n",
    "                    'prefix': prefix_text,\n",
    "                    'ground_truth': target_text,\n",
    "                    'generated': generated_text,\n",
    "                    'rouge1': scores['rouge1'].fmeasure,\n",
    "                    'rouge2': scores['rouge2'].fmeasure,\n",
    "                    'rougeL': scores['rougeL'].fmeasure\n",
    "                })\n",
    "                \n",
    "                examples_shown += 1\n",
    "            \n",
    "            if examples_shown >= num_examples:\n",
    "                break\n",
    "\n",
    "# Сохраняем примеры в JSON\n",
    "with open(PATHS['test_examples'], 'w', encoding='utf-8') as f:\n",
    "    json.dump(examples_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nПримеры сохранены в: {PATHS['test_examples']}\")\n",
    "print(\"Оценка завершена\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756ee5f3",
   "metadata": {},
   "source": [
    "### Вывод: дополнение осмысленны. ROUGE низкая, но это неудивительно, т.к. в такиъх твиттах смысла не всегда много, тут perplexity и у человека высокая будет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0081fc",
   "metadata": {},
   "source": [
    "### Использование предобученного трансформера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8b0ce53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "Device: cuda\n",
      "\n",
      "Загрузка DistilGPT2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Подсчет loss на validation set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c290f11ab7d42ac91a85f0fa3cf4749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing loss:   0%|          | 0/433 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPT2 Loss: 7.4887\n",
      "GPT2 Perplexity: 1787.65\n",
      "\n",
      "Оценка ROUGE на validation set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b64e5ef4f643328468de0864527fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DistilGPT2 Generation:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "РЕЗУЛЬТАТЫ DistilGPT2 НА VALIDATION SET\n",
      "================================================================================\n",
      "Loss:       7.4887\n",
      "Perplexity: 1787.65\n",
      "ROUGE-1: 0.0645\n",
      "ROUGE-2: 0.0060\n",
      "ROUGE-L: 0.0591\n",
      "================================================================================\n",
      "\n",
      "ПРИМЕРЫ ГЕНЕРАЦИИ DistilGPT2:\n",
      "================================================================================\n",
      "\n",
      "Пример 1:\n",
      "Префикс: nice to tweet you! you ' ve got me singing quottonight i ' m gonna party like it ' s 1999... quot it\n",
      "Ground Truth: won ' t get out of my head!\n",
      "GPT2: ...\n",
      "\n",
      "\n",
      "\n",
      "I am a long time\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Пример 2:\n",
      "Префикс: brill poor rabbit. maybe we should get a frog as well\n",
      "Ground Truth: to eat the flies?\n",
      "GPT2: , then we can make a frog ourselves.\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Пример 3:\n",
      "Префикс: ah yes, space is so limited here! must work with what i have!\n",
      "Ground Truth: yours is looking great, too!\n",
      "GPT2: if i have to try it, i will not\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Пример 4:\n",
      "Префикс: cool. did i see something about a free lunch if i sign up for nbc4\n",
      "Ground Truth: rewards the weather is gorgeous\n",
      "GPT2: . I can't remember if i noticed a sign\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Пример 5:\n",
      "Префикс: i know! the poor thing must ' ve been so scared! all these huge things coming towards it! accidentaly overslept had to drive this morningstare at the sun. 5 page paper to start and finish in an hour\n",
      "Ground Truth: . oh joy. why i cant find dear friend i need her to\n",
      "GPT2: . 7 page paper to finish, a page book\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Примеры сохранены в: C:\\Users\\Alexandra\\Desktop\\text_autocompletion\\models\\gpt2_generation_examples.json\n",
      "Готово\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Сравнение с baseline: DistilGPT2.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Параметры для GPT2\n",
    "\n",
    "\n",
    "gpt2_params = {\n",
    "    'model_name': 'distilgpt2',\n",
    "    'num_samples': 100,\n",
    "    'max_new_tokens': 10,\n",
    "    'split_ratio': 0.75\n",
    "}\n",
    "\n",
    "\n",
    "# Загрузка данных\n",
    "\n",
    "\n",
    "print(\"Загрузка данных...\")\n",
    "with open(PATHS['val_dataset'], 'rb') as f:\n",
    "    val_dataset = pickle.load(f)\n",
    "with open(PATHS['tokenizer'], 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Загрузка DistilGPT2\n",
    "\n",
    "\n",
    "print(\"\\nЗагрузка DistilGPT2...\")\n",
    "tokenizer_gpt = AutoTokenizer.from_pretrained(gpt2_params['model_name'])\n",
    "tokenizer_gpt.pad_token = tokenizer_gpt.eos_token\n",
    "\n",
    "model_gpt = AutoModelForCausalLM.from_pretrained(gpt2_params['model_name']).to(device)\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_gpt,\n",
    "    tokenizer=tokenizer_gpt,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer_gpt.pad_token_id, reduction='none')\n",
    "\n",
    "\n",
    "# Функция генерации\n",
    "\n",
    "\n",
    "def generate_continuation(text, max_new_tokens=10):\n",
    "    \"\"\"Генерирует продолжение текста (последние 25%).\"\"\"\n",
    "    words = text.split()\n",
    "    split_idx = int(len(words) * gpt2_params['split_ratio'])\n",
    "    \n",
    "    input_text = \" \".join(words[:split_idx])\n",
    "    target_text = \" \".join(words[split_idx:])\n",
    "    \n",
    "    result = generator(\n",
    "        input_text,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        top_k=MODEL_CONFIG['top_k'],\n",
    "        temperature=MODEL_CONFIG['temperature']\n",
    "    )\n",
    "    \n",
    "    generated_full = result[0][\"generated_text\"]\n",
    "    generated_tail = generated_full[len(input_text):].strip()\n",
    "    \n",
    "    return input_text, target_text, generated_tail\n",
    "\n",
    "\n",
    "\n",
    "# Подсчет loss на validation set\n",
    "\n",
    "\n",
    "print(\"\\nПодсчет loss на validation set...\")\n",
    "val_loader = DataLoader(val_dataset, batch_size=TRAINING_CONFIG['batch_size'], shuffle=False, num_workers=0)\n",
    "\n",
    "model_gpt.eval()\n",
    "val_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for prefix, target, mask in tqdm(val_loader, desc=\"Computing loss\"):\n",
    "        # Токенизируем prefix для GPT2\n",
    "        prefix_text_batch = [tokenizer.decode(p.tolist(), skip_special_tokens=True) for p in prefix]\n",
    "        target_text_batch = [tokenizer.decode(t.tolist(), skip_special_tokens=True) for t in target]\n",
    "        \n",
    "        # Объединяем prefix + target для GPT2\n",
    "        full_text_batch = [p + \" \" + t for p, t in zip(prefix_text_batch, target_text_batch)]\n",
    "        \n",
    "        # Токенизируем для GPT2\n",
    "        inputs = tokenizer_gpt(full_text_batch, return_tensors='pt', padding=True, truncation=True, max_length=MODEL_CONFIG['max_length'])\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_gpt(**inputs, labels=inputs['input_ids'])\n",
    "        val_loss += outputs.loss.item()\n",
    "\n",
    "val_loss /= len(val_loader)\n",
    "val_perplexity = np.exp(val_loss)\n",
    "\n",
    "print(f\"\\nGPT2 Loss: {val_loss:.4f}\")\n",
    "print(f\"GPT2 Perplexity: {val_perplexity:.2f}\")\n",
    "\n",
    "# Оценка ROUGE на validation set\n",
    "\n",
    "\n",
    "print(\"\\nОценка ROUGE на validation set...\")\n",
    "\n",
    "num_samples = gpt2_params['num_samples']\n",
    "sample_indices = np.random.choice(len(val_dataset), num_samples, replace=False)\n",
    "\n",
    "all_preds, all_refs = [], []\n",
    "\n",
    "for idx in tqdm(sample_indices, desc=\"DistilGPT2 Generation\"):\n",
    "    prefix, target, _ = val_dataset[idx]\n",
    "    \n",
    "    prefix_text = tokenizer.decode(prefix.tolist(), skip_special_tokens=True)\n",
    "    target_text = tokenizer.decode(target.tolist(), skip_special_tokens=True)\n",
    "    full_text = prefix_text + \" \" + target_text\n",
    "    \n",
    "    _, gt, pred = generate_continuation(full_text, max_new_tokens=gpt2_params['max_new_tokens'])\n",
    "    \n",
    "    all_preds.append(pred)\n",
    "    all_refs.append(gt)\n",
    "\n",
    "# ROUGE метрики\n",
    "gpt_rouge = rouge.compute(predictions=all_preds, references=all_refs)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"РЕЗУЛЬТАТЫ DistilGPT2 НА VALIDATION SET\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Loss:       {val_loss:.4f}\")\n",
    "print(f\"Perplexity: {val_perplexity:.2f}\")\n",
    "print(f\"ROUGE-1: {gpt_rouge['rouge1']:.4f}\")\n",
    "print(f\"ROUGE-2: {gpt_rouge['rouge2']:.4f}\")\n",
    "print(f\"ROUGE-L: {gpt_rouge['rougeL']:.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Примеры генерации\n",
    "\n",
    "\n",
    "print(\"\\nПРИМЕРЫ ГЕНЕРАЦИИ DistilGPT2:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "examples_data = []\n",
    "for i in range(min(5, num_samples)):\n",
    "    idx = sample_indices[i]\n",
    "    prefix, target, _ = val_dataset[idx]\n",
    "    \n",
    "    prefix_text = tokenizer.decode(prefix.tolist(), skip_special_tokens=True)\n",
    "    target_text = tokenizer.decode(target.tolist(), skip_special_tokens=True)\n",
    "    full_text = prefix_text + \" \" + target_text\n",
    "    \n",
    "    inp, gt, pred = generate_continuation(full_text, max_new_tokens=gpt2_params['max_new_tokens'])\n",
    "    \n",
    "    print(f\"\\nПример {i+1}:\")\n",
    "    print(f\"Префикс: {inp}\")\n",
    "    print(f\"Ground Truth: {gt}\")\n",
    "    print(f\"GPT2: {pred}\")\n",
    "    print(\"─\"*80)\n",
    "    \n",
    "    # Сохраняем как словарь\n",
    "    examples_data.append({\n",
    "        'example_num': i + 1,\n",
    "        'prefix': inp,\n",
    "        'ground_truth': gt,\n",
    "        'gpt2_generated': pred\n",
    "    })\n",
    "\n",
    "# Сохраняем примеры в JSON\n",
    "with open(PATHS['gpt2_examples'], 'w', encoding='utf-8') as f:\n",
    "    json.dump(examples_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nПримеры сохранены в: {PATHS['gpt2_examples']}\")\n",
    "print(\"Готово\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0992a9d8",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc6eb8b",
   "metadata": {},
   "source": [
    "- ROUGE-1 метрика низка у обеих моделей (обученная нами LSTM и DistilGPT2: 0.6 ROUGE1 у обеих), что указывает на сложность задачи точного воспроизведения текста. Это сложно даже для человека. Несмотря на, это результаты получились довольно адекватные, у нашей модели даже немного адекватнее DistilGPT2, на мой субъективный взгляд.\n",
    "- DistilGPT2 показывает немного лучшие результаты по ROUGE-1,  что может быть связано с его предобучением на гораздо более объемном корпусе.  \n",
    "- LSTM демонстрирует конкурентоспособные результаты, особенно учитывая её меньший размер и отсутствие предобучения.\n",
    "\n",
    "Для нашего приложения можно рассчитывать на LSTM, особенно если дообучить ее на более логичных текстах и на большем корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3279747c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c400ea3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0c8039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8dc268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
